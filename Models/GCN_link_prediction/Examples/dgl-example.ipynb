{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may only be useful as an illustration for how to apply index features and emebddings into graph convolutions. Look at the code marked with `******` to see how this works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "\n",
    "import torch\n",
    "import dgl\n",
    "import numpy as np \n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 1000\n",
    "n_items = 1000\n",
    "n_kcs = 100\n",
    "\n",
    "kc_min = 1\n",
    "kc_max = 10\n",
    "\n",
    "n_prob_dists = 5\n",
    "n_ics = n_items + n_kcs \n",
    "\n",
    "q_dict = dict()\n",
    "probs = np.random.dirichlet(np.ones(n_kcs), size=n_prob_dists)\n",
    "for item_id in range(n_items): \n",
    "    kc_samples = np.random.choice(\n",
    "        a=np.arange(n_kcs), \n",
    "        size=np.random.randint(kc_min, kc_max, 1), \n",
    "        p=probs[np.random.randint(0, n_prob_dists)],\n",
    "        replace=False,\n",
    "    )\n",
    "    q_dict[item_id] = kc_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3515],\n",
       "        [0.2164],\n",
       "        [0.5256],\n",
       "        [0.4713],\n",
       "        [0.4606],\n",
       "        [0.8242],\n",
       "        [0.3626],\n",
       "        [0.5044],\n",
       "        [0.6287],\n",
       "        [0.3689],\n",
       "        [0.4438],\n",
       "        [0.7753],\n",
       "        [0.4904],\n",
       "        [0.7105],\n",
       "        [0.6538],\n",
       "        [0.5350],\n",
       "        [0.7593],\n",
       "        [0.4709],\n",
       "        [0.9232],\n",
       "        [0.6271],\n",
       "        [0.2440],\n",
       "        [0.6542],\n",
       "        [0.8611],\n",
       "        [0.1874],\n",
       "        [0.7029],\n",
       "        [0.6656],\n",
       "        [0.3428],\n",
       "        [0.7177],\n",
       "        [0.2185],\n",
       "        [0.3276],\n",
       "        [0.3766],\n",
       "        [0.4166],\n",
       "        [0.8782],\n",
       "        [0.6927],\n",
       "        [0.8452],\n",
       "        [0.6744],\n",
       "        [0.6576],\n",
       "        [0.2369],\n",
       "        [0.2931],\n",
       "        [0.6390],\n",
       "        [0.2596],\n",
       "        [0.5329],\n",
       "        [0.7306],\n",
       "        [0.6138],\n",
       "        [0.5707],\n",
       "        [0.4800],\n",
       "        [0.8383],\n",
       "        [0.8356],\n",
       "        [0.9345],\n",
       "        [0.2001],\n",
       "        [0.9314],\n",
       "        [0.9457],\n",
       "        [0.5737],\n",
       "        [0.2621],\n",
       "        [0.7222],\n",
       "        [0.4506],\n",
       "        [0.5510],\n",
       "        [0.8465],\n",
       "        [0.7828],\n",
       "        [0.4529],\n",
       "        [0.6843],\n",
       "        [0.5518],\n",
       "        [0.7997],\n",
       "        [0.8350],\n",
       "        [0.7665],\n",
       "        [0.4417],\n",
       "        [0.7769],\n",
       "        [0.5149],\n",
       "        [0.6003],\n",
       "        [0.5069],\n",
       "        [0.8145],\n",
       "        [0.6691],\n",
       "        [0.4810],\n",
       "        [0.2735],\n",
       "        [0.8042],\n",
       "        [0.3824],\n",
       "        [0.5355],\n",
       "        [0.5243],\n",
       "        [0.3290],\n",
       "        [0.6776],\n",
       "        [0.7728],\n",
       "        [0.7726],\n",
       "        [0.2224],\n",
       "        [0.7164],\n",
       "        [0.2538],\n",
       "        [0.4182],\n",
       "        [0.4790],\n",
       "        [0.6759],\n",
       "        [0.7789],\n",
       "        [0.4075],\n",
       "        [0.7733],\n",
       "        [0.2716],\n",
       "        [0.9374],\n",
       "        [0.4542],\n",
       "        [0.6463],\n",
       "        [0.4192],\n",
       "        [0.7308],\n",
       "        [0.5542],\n",
       "        [0.5495],\n",
       "        [0.7269]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl.nn import GraphConv\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "def q_dict_to_sp_extended_csr(q_dict) -> sp.spmatrix: \n",
    "    # Assumes standardised IDs\n",
    "    item_ids = []\n",
    "    kc_ids = []\n",
    "    for item_id, item_kcs in q_dict.items(): \n",
    "        for kc_id in item_kcs: \n",
    "            item_ids.append(item_id)\n",
    "            kc_ids.append(kc_id)\n",
    "    item_ids = np.asarray(item_ids)\n",
    "    kc_ids = np.asarray(kc_ids)\n",
    "    data = np.ones_like(item_ids).astype(float)\n",
    "    \n",
    "    # Convenience vars \n",
    "    n_items = len(q_dict)\n",
    "    n_kcs = len(set(kc_ids))\n",
    "    n_ics = n_items + n_kcs\n",
    "\n",
    "    # Make the n_items x n_kcs matrix\n",
    "    q_matrix = sp.csr_matrix((data, (item_ids, kc_ids)), shape=(n_items, n_kcs))\n",
    "    \n",
    "    # make the n_ics x n_ics matrix; offset KC IDs by n_items\n",
    "    q_matrix_extended = sp.csr_matrix((data, (item_ids, kc_ids + n_items)), shape=(n_ics, n_ics))\n",
    "    q_matrix_extended += q_matrix_extended.T + sp.eye(n_ics)\n",
    "\n",
    "    return q_matrix_extended\n",
    "\n",
    "\n",
    "\n",
    "class GCQEmbedding(nn.Module):\n",
    "    def __init__(self, q_dict, n_feats=10, n_out=3, n_levels=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert isinstance(q_dict, dict)\n",
    "        \n",
    "        # Get the sparse extended matrix, and construct the DGL graph object\n",
    "        self.q_matrix_extended = q_dict_to_sp_extended_csr(q_dict=q_dict)\n",
    "        self.dgl_graph = dgl.from_scipy(self.q_matrix_extended, eweight_name='w')\n",
    "        \n",
    "        # Instantiate the node embeddings, graph convolutions, and prediction modules\n",
    "        # NIKHIL: ********* \\/\n",
    "        self.node_embeddings = nn.Embedding(self.dgl_graph.num_nodes(), n_feats)\n",
    "        self.gconvs = nn.ModuleList()\n",
    "        assert n_levels > 0\n",
    "        for _ in range(n_levels):\n",
    "            self.gconvs.append(GraphConv(n_feats, n_feats))\n",
    "        self.pred = nn.Linear(n_feats, n_out)\n",
    "        \n",
    "    def graph_embeddings(self, embeddings=None):\n",
    "        # Calculate the graph embeddings\n",
    "        zz = self.node_embeddings(torch.arange(self.dgl_graph.num_nodes()))\n",
    "        for gconv in self.gconvs: \n",
    "            zz = gconv(self.dgl_graph, zz.relu())\n",
    "        return self.pred(zz.relu())\n",
    "\n",
    "    def forward(self, item_ids):\n",
    "        # Calculate the predicted embeddings\n",
    "        embeddings = self.graph_embeddings()\n",
    "        # return embeddings[item_ids]\n",
    "        pred = nn.functional.embedding(weight=embeddings, input=item_ids)\n",
    "        return pred\n",
    "    \n",
    "class GCN_MovieLens(nn.Module): \n",
    "    def __init__(self, n_users, n_items, q_dict=None, n_feats=20, n_levels=2, k=3): \n",
    "        super().__init__()\n",
    "        self.user_embeddings = nn.Embedding(n_users, n_feats) \n",
    "        self.item_embeddings = GCQEmbedding(\n",
    "            q_dict=q_dict, \n",
    "            n_feats=n_feats,\n",
    "            n_levels=n_levels,\n",
    "            n_out=n_feats\n",
    "        )\n",
    "        \n",
    "    def forward(self, user_ids, item_ids): \n",
    "        user_embeddings = self.user_embeddings(user_ids)\n",
    "        item_embeddings = self.item_embeddings(item_ids)\n",
    "        return torch.cat([user_embeddings, item_embeddings], dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GCN_IRT(nn.Module): \n",
    "    def __init__(self, n_users, n_items, q_dict=None, n_feats=20, n_levels=2, k=3): \n",
    "        super().__init__()\n",
    "        self.user_embeddings = nn.Embedding(n_users, 1) \n",
    "        self.item_embeddings = GCQEmbedding(\n",
    "            q_dict=q_dict, \n",
    "            n_feats=n_feats,\n",
    "            n_levels=n_levels,\n",
    "            n_out=k\n",
    "        )\n",
    "        \n",
    "        self.k = k\n",
    "        \n",
    "        # Note: Can easily toggle on/off GCN components by toggling between embedding \n",
    "        #       types with the same forward signature\n",
    "        # if q_dict is None:\n",
    "        #     self.item_embeddings = nn.Embedding(n_items, k)\n",
    "        \n",
    "    def forward(self, user_ids, item_ids): \n",
    "        # User\n",
    "        ability = self.user_embeddings(user_ids)\n",
    "        \n",
    "        # Item\n",
    "        item_params = self.item_embeddings(item_ids)\n",
    "        assert item_params.shape[1] == self.k\n",
    "        diff = item_params[:, [0]]\n",
    "        disc = item_params[:, [1]].exp()           # Helps identifiability\n",
    "        guess = item_params[:, [2]].sigmoid() / 4  # Helps identifiability\n",
    "        \n",
    "        # 2PL IRT prob\n",
    "        logits = (ability - diff) * disc\n",
    "        prob = logits.sigmoid()\n",
    "        \n",
    "        # 3PL IRT prob\n",
    "        return guess + (1 - guess) * prob\n",
    "\n",
    "\n",
    "model = GCN_IRT(\n",
    "    n_users=n_users, \n",
    "    n_items=n_items, \n",
    "    q_dict=q_dict, \n",
    ")\n",
    "\n",
    "n_ints = 100\n",
    "\n",
    "user_ids = torch.randint(0, n_users, (n_ints,))\n",
    "item_ids = torch.randint(0, n_items, (n_ints,))\n",
    "\n",
    "pp = model(user_ids=user_ids, item_ids=item_ids).detach()\n",
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
